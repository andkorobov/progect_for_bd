# progect

Пару слов о возможностях, которые были реализованы:
* Чтение файлов формата vowpal wabbit. Вообще я старался сделать что-то подолбное vowpal wabbit. Путь к файлу подаётся либо первым аргументом командной сторки, либо используя аргумент: "-d file_path"
* Используется статистический градиент: 
  $$ w_{n+1} = w_n - grad(Los(w)) * \frac \mu n   $$ 
  Где $\mu$ задаётся с помощью аргумента командной строки "--initial_t"
* Все фичи воспринимаются как стоки, а затем хэшируются. Логарифм виличины хэша передаётся через аргумент командной строки "--bit_precision".
* Есть возможность создавать квадратичные фичи по аналогии с vowpal wabbit, используя аргумент командной строки "--quadratic arg"
* Для запуска в режиме тестирования нужно использовать аргумент командной строки "--testonly"
* Алгоритм может несколько раз проходить по файлу. Для того, чтобы задать колличество проходов нужно использовать аргумент командной строки "--passes"
* Алгоритм умеет работать с двумя функциями потерь: квадратичной и логистической. Чтобы задать нужно истользовать аргумент "--loss_function arg"
* Реализовано два вида регуляризации: L1 и L2. Соответственно задаются с помощью аргументов "--l1 arg" и "--l12 arg"
* Чтобы задать путь к файлу результирующей модели, используется аргумент "--final_regressor"
* Чтобы задать путь к файлу с предсказанием, используется аргумент "--predictions"
* Вывод возможен рёх видов identity (число от $-\infty$ до $+\infty$), logistic (число от 0 до 1) or glf1 (число от -1 до 1). Для этого используется агрумент "--link arg"
* При первом проходе файл кешируется. Затем уше проход веется по файлу с кешем, не используя исходный (файл с кешем примерно в полтора разо меньше и в более удобном формате для чтения). Можно задать путь для файла с помощью команды "--cache_file arg"
* Есть возможность использовать адаптивный learning rate (с помощью команды "--adaptive")
