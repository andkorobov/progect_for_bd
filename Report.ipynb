{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Репозиторий https://github.com/andkorobov/progect_for_bd/**\n",
    "\n",
    "\n",
    "## Пару слов о возможностях, которые были реализованы:\n",
    "* Чтение файлов формата vowpal wabbit. Вообще я старался сделать что-то подолбное vowpal wabbit. Путь к файлу подаётся либо первым аргументом командной сторки, либо используя аргумент: \"-d file_path\"\n",
    "* Используется статистический градиент: \n",
    "  $$ w_{n+1} = w_n - grad(Los(w)) * \\frac \\mu n   $$ \n",
    "  Где $\\mu$ задаётся с помощью аргумента командной строки \"--initial_t\"\n",
    "* Все фичи воспринимаются как стоки, а затем хэшируются. Логарифм виличины хэша передаётся через аргумент командной строки \"--bit_precision\".\n",
    "* Есть возможность создавать квадратичные фичи по аналогии с vowpal wabbit, используя аргумент командной строки \"--quadratic arg\"\n",
    "* Для запуска в режиме тестирования нужно использовать аргумент командной строки \"--testonly\"\n",
    "* Алгоритм может несколько раз проходить по файлу. Для того, чтобы задать колличество проходов нужно использовать аргумент командной строки \"--passes\"\n",
    "* Алгоритм умеет работать с двумя функциями потерь: квадратичной и логистической. Чтобы задать нужно истользовать аргумент \"--loss_function arg\"\n",
    "* Реализовано два вида регуляризации: L1 и L2. Соответственно задаются с помощью аргументов \"--l1 arg\" и \"--l12 arg\"\n",
    "* Чтобы задать путь к файлу результирующей модели, используется аргумент \"--final_regressor\"\n",
    "* Чтобы задать путь к файлу с предсказанием, используется аргумент \"--predictions\"\n",
    "* Вывод возможен рёх видов identity (число от $-\\infty$ до $+\\infty$), logistic (число от 0 до 1) or glf1 (число от -1 до 1). Для этого используется агрумент \"--link arg\"\n",
    "* При первом проходе файл кешируется. Затем уше проход веется по файлу с кешем, не используя исходный (файл с кешем примерно в полтора разо меньше и в более удобном формате для чтения). Можно задать путь для файла с помощью команды \"--cache_file arg\"\n",
    "* Есть возможность использовать адаптивный learning rate (с помощью команды \"--adaptive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Компиляция \n",
    "Использовались возможности c++11. Рекомендуется компилировать следующем образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!g++ -std=c++0x -O3 main.cpp -o main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример запуска\n",
    "\n",
    "В качестве примера рассмотрим известную задачу Titanic: https://www.kaggle.com/c/titanic. \n",
    "\n",
    "Для подготовки выборки я использовал скрипты из статьи: https://habrahabr.ru/company/mlclass/blog/248779/\n",
    "\n",
    "Для примера воспользуемся произвольным параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path = /ssd_data/titanic/train.vw\n",
      "loss_function = logistic\n",
      "hash_size = 16777216\n",
      "passes = 10\n",
      "initial_t = 0.5\n",
      "l1 = 0.001\n",
      "l2 = 0.001\n",
      "testonly = 0\n",
      "adaptive = 1\n",
      "final_regressor = /ssd_data/titanic/model\n",
      "cache_file = /ssd_data/titanic/train.vw.cache\n",
      "link = logistic\n",
      "quadratic = [ff]\n",
      "\n",
      "Iteration num   | average loss  |  from last    |  lable        | yPredicted    | current t\n",
      "------------------------------------------------------------------------------------------------\n",
      "2\t\t| 11.09657383\t| 22.19314766\t| 1.00000000\t| 0.00000000\t| 0.25000000\n",
      "4\t\t| 8.48564816\t| 5.87472200\t| 1.00000000\t| 0.02432220\t| 0.12500000\n",
      "8\t\t| 4.24332428\t| 0.00100060\t| -1.00000000\t| 0.00038517\t| 0.06250000\n",
      "16\t\t| 2.45841146\t| 0.67349821\t| 1.00000000\t| 0.69759506\t| 0.03125000\n",
      "32\t\t| 1.74550629\t| 1.03260100\t| 1.00000000\t| 0.99982423\t| 0.01562500\n",
      "64\t\t| 1.04915321\t| 0.35280034\t| -1.00000000\t| 0.00007099\t| 0.00781250\n",
      "128\t\t| 1.01093531\t| 0.97271782\t| 1.00000000\t| 0.00036033\t| 0.00390625\n",
      "256\t\t| 0.95923269\t| 0.90753013\t| 1.00000000\t| 0.92704004\t| 0.00195312\n",
      "512\t\t| 1.00256193\t| 1.04589093\t| -1.00000000\t| 0.01244552\t| 0.00097656\n",
      "1024\t\t| 0.94291270\t| 0.88326347\t| -1.00000000\t| 0.11197536\t| 0.00048828\n",
      "2048\t\t| 0.92760152\t| 0.91229105\t| -1.00000000\t| 0.01455623\t| 0.00024414\n",
      "4096\t\t| 0.91894978\t| 0.91029739\t| -1.00000000\t| 0.00804607\t| 0.00012207\n",
      "8192\t\t| 0.90624875\t| 0.89354646\t| 1.00000000\t| 0.85833037\t| 0.00006104\n",
      "\n",
      "Run finished\n"
     ]
    }
   ],
   "source": [
    "!./main --loss_function logistic -d /ssd_data/titanic/train.vw \\\n",
    "--passes 10 --bit_precision 24 -l2 0.001 -l1 0.001 --final_regressor \\\n",
    "/ssd_data/titanic/model --link logistic --cache --adaptive --quadratic ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path = /ssd_data/titanic/test.vw\r\n",
      "loss_function = logistic\r\n",
      "hash_size = 16777216\r\n",
      "passes = 1\r\n",
      "initial_t = 0.5\r\n",
      "l1 = 0.001\r\n",
      "l2 = 0.001\r\n",
      "testonly = 1\r\n",
      "adaptive = 0\r\n",
      "final_regressor = /ssd_data/titanic/model\r\n",
      "predictions = /ssd_data/titanic/predict.txt\r\n",
      "link = logistic\r\n",
      "quadratic = [ff]\r\n",
      "\r\n",
      "Iteration num   | average loss  |  from last    |  lable        | yPredicted    | current t\r\n",
      "------------------------------------------------------------------------------------------------\r\n",
      "2\t\t| 6.59966850\t| 13.19933701\t| 1.00000000\t| 0.75588983\t| 0.25000000\r\n",
      "4\t\t| 8.66672611\t| 10.73378468\t| 1.00000000\t| 0.00000000\t| 0.12500000\r\n",
      "8\t\t| 6.89986324\t| 5.13300133\t| 1.00000000\t| 0.00048999\t| 0.06250000\r\n",
      "16\t\t| 5.79839802\t| 4.69693327\t| 1.00000000\t| 0.99032623\t| 0.03125000\r\n",
      "32\t\t| 5.99392796\t| 6.18945980\t| 1.00000000\t| 0.00040873\t| 0.01562500\r\n",
      "64\t\t| 5.98691225\t| 5.97989559\t| 1.00000000\t| 0.51617122\t| 0.00781250\r\n",
      "128\t\t| 5.55765676\t| 5.12839937\t| 1.00000000\t| 0.62533611\t| 0.00390625\r\n",
      "256\t\t| 5.65012741\t| 5.74259281\t| 1.00000000\t| 0.00017552\t| 0.00195312\r\n",
      "\r\n",
      "Run finished\r\n"
     ]
    }
   ],
   "source": [
    "!./main -d /ssd_data/titanic/test.vw  --final_regressor /ssd_data/titanic/model \\\n",
    "--predictions /ssd_data/titanic/predict.txt --testonly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что же вышло:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r\n",
      "0.75589\r\n",
      "0.000122357\r\n",
      "0\r\n",
      "0.890314\r\n",
      "0\r\n",
      "0.444748\r\n",
      "0.000489988\r\n",
      "0.916958\r\n",
      "0\r\n"
     ]
    }
   ],
   "source": [
    "! head /ssd_data/titanic/predict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для чтения результата:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   7.55890000e-01,   1.22357000e-04,\n",
       "         0.00000000e+00,   8.90314000e-01,   0.00000000e+00,\n",
       "         4.44748000e-01,   4.89988000e-04,   9.16958000e-01,\n",
       "         0.00000000e+00])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_predict(path):\n",
    "    predict = []\n",
    "    with open(path) as predict_file:\n",
    "        for line in predict_file.readlines():\n",
    "            predict.append(float(line))\n",
    "    return np.array(predict)\n",
    "            \n",
    "read_predict('/ssd_data/titanic/predict.txt')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним с тем что было:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('/ssd_data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что результатов тут нет. Поэтому было решено воспользоваться уже готовым решением и сравнивать с ним: https://www.kaggle.com/benhamner/titanic/random-forest-benchmark-r/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('/ssd_data/titanic/1_random_forest_r_submission .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0\n",
       "5          897         0\n",
       "6          898         0\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "посчитаем logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418,) (418,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAJoCAYAAAAnEZb5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f986d495f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_res():\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    scores = read_predict('/ssd_data/titanic/predict.txt')\n",
    "    y_pred = np.array([[1 - score, score] for score in scores])\n",
    "    y_true = test_csv['Survived'].values\n",
    "    print y_true.shape, scores.shape\n",
    " \n",
    "    _log_loss = log_loss(y_true, y_pred)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, 1 - scores, pos_label=0)\n",
    "    roc_auc= metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='log_loss = {}, ROC AUC = {}'.format(_log_loss, roc_auc), alpha=0.5, linewidth=2)\n",
    "\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    \n",
    "plot_res()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получился вполне неплохой результат. Попробуем запустить без каких-то параметров. Будем использовать subprocess.Popen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import PIPE, Popen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_lerning(input_file='/ssd_data/titanic/train.vw', \n",
    "               final_regressor='/ssd_data/titanic/model',\n",
    "               l1=0.001,\n",
    "               l2=0.001,\n",
    "               configs = {}):\n",
    "    line = './main -d {input_file} --final_regressor {final_regressor}'\\\n",
    "           .format(input_file=input_file, final_regressor=final_regressor)\n",
    "    if l1:\n",
    "        line += ' -l1 {}'.format(l1)\n",
    "    if l2:\n",
    "        line += ' -l2 {}'.format(l2)\n",
    "    for k, v in configs.items():\n",
    "        line += ' --{}'.format(k)\n",
    "        if v is not None:\n",
    "            line += ' {}'.format(v)\n",
    "\n",
    "    Popen(line.split()).wait()\n",
    "    \n",
    "def run_predict(input_file='/ssd_data/titanic/test.vw', \n",
    "               final_regressor='/ssd_data/titanic/model',\n",
    "               predictions='/ssd_data/titanic/predict.txt'):\n",
    "    line = './main -d {}  --final_regressor {} --predictions {} --testonly'\\\n",
    "            .format(input_file, final_regressor, predictions)\n",
    "\n",
    "    Popen(line.split()).wait()\n",
    "\n",
    "def get_log_loss(predictions='/ssd_data/titanic/predict.txt'):\n",
    "    scores = read_predict('/ssd_data/titanic/predict.txt')\n",
    "    y_pred = np.array([[1 - score, score] for score in scores])\n",
    "    y_true = test_csv['Survived'].values\n",
    "    return log_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39233247408345967"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_lerning(configs={'loss_function': 'logistic', \n",
    "                     'passes': 10,\n",
    "                     'bit_precision': 24,\n",
    "                     'link': 'logistic',\n",
    "                     'cache': None,\n",
    "                     'adaptive': None,\n",
    "                     'quadratic': 'ff'})\n",
    "run_predict()\n",
    "get_log_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось тоже самое. Возьмем квадратичную функцию ошибки: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28557430165952835"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_config(configs):\n",
    "    run_lerning(configs=configs)\n",
    "    run_predict()\n",
    "    return get_log_loss()\n",
    "check_config(configs={'passes': 10,\n",
    "                      'bit_precision': 24,\n",
    "                      'link': 'logistic',\n",
    "                      'cache': None,\n",
    "                      'adaptive': None,\n",
    "                      'quadratic': 'ff'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили результат ближе к случайному лесу. Уберем теперь quadratic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46986103142540991"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_config(configs={'passes': 10,\n",
    "                      'bit_precision': 24,\n",
    "                      'link': 'logistic',\n",
    "                      'cache': None,\n",
    "                      'adaptive': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало хуже. Если убирать adaptive, то расходится (adaptive в дополнение делает нормализацию). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим для различных регуляризаций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1e-06 10 logistic 0.377856505718\n",
      "1e-06 1e-06 10 quadratic 0.285579402274\n",
      "1e-06 0.0001 10 logistic 0.377481942511\n",
      "1e-06 0.0001 10 quadratic 0.285579308369\n",
      "1e-06 0.01 10 logistic 0.354571848541\n",
      "1e-06 0.01 10 quadratic 0.285572354108\n",
      "1e-06 1.0 10 logistic 0.276531742992\n",
      "1e-06 1.0 10 quadratic 0.28488674483\n",
      "1e-06 100.0 10 logistic 0.321280675346\n",
      "1e-06 100.0 10 quadratic 0.264252848002\n",
      "1e-06 10000.0 10 logistic 0.347533532568\n",
      "1e-06 10000.0 10 quadratic 0.319150340102\n",
      "0.0001 1e-06 10 logistic 0.382602164256\n",
      "0.0001 1e-06 10 quadratic 0.285578933075\n",
      "0.0001 0.0001 10 logistic 0.382307084408\n",
      "0.0001 0.0001 10 quadratic 0.285578914185\n",
      "0.0001 0.01 10 logistic 0.356680798591\n",
      "0.0001 0.01 10 quadratic 0.285571931625\n",
      "0.0001 1.0 10 logistic 0.276544395309\n",
      "0.0001 1.0 10 quadratic 0.284886252136\n",
      "0.0001 100.0 10 logistic 0.321281113255\n",
      "0.0001 100.0 10 quadratic 0.264252860778\n",
      "0.0001 10000.0 10 logistic 0.34753357459\n",
      "0.0001 10000.0 10 quadratic 0.31915037975\n",
      "0.01 1e-06 10 logistic 0.396877501102\n",
      "0.01 1e-06 10 quadratic 0.285535895522\n",
      "0.01 0.0001 10 logistic 0.396858577779\n",
      "0.01 0.0001 10 quadratic 0.28553597099\n",
      "0.01 0.01 10 logistic 0.394961987419\n",
      "0.01 0.01 10 quadratic 0.285528919763\n",
      "0.01 1.0 10 logistic 0.277992297239\n",
      "0.01 1.0 10 quadratic 0.284843593612\n",
      "0.01 100.0 10 logistic 0.32132882236\n",
      "0.01 100.0 10 quadratic 0.264254846591\n",
      "0.01 10000.0 10 logistic 0.347537009378\n",
      "0.01 10000.0 10 quadratic 0.319151505207\n",
      "1.0 1e-06 10 logistic 1.09356564609\n",
      "1.0 1e-06 10 quadratic 0.281963828407\n",
      "1.0 0.0001 10 logistic 1.09355947189\n",
      "1.0 0.0001 10 quadratic 0.281963770835\n",
      "1.0 0.01 10 logistic 1.0929395086\n",
      "1.0 0.01 10 quadratic 0.281957773138\n",
      "1.0 1.0 10 logistic 1.52086352408\n",
      "1.0 1.0 10 quadratic 0.281205872186\n",
      "1.0 100.0 10 logistic 0.337192348746\n",
      "1.0 100.0 10 quadratic 0.264819563921\n",
      "1.0 10000.0 10 logistic 0.347966951667\n",
      "1.0 10000.0 10 quadratic 0.319264147673\n",
      "100.0 1e-06 10 logistic 8.93522168013\n",
      "100.0 1e-06 10 quadratic 0.944223245102\n",
      "100.0 0.0001 10 logistic 8.93522245834\n",
      "100.0 0.0001 10 quadratic 0.944223472026\n",
      "100.0 0.01 10 logistic 8.93530811666\n",
      "100.0 0.01 10 quadratic 0.944242466083\n",
      "100.0 1.0 10 logistic 8.9486649242\n",
      "100.0 1.0 10 quadratic 0.946125429689\n",
      "100.0 100.0 10 logistic 9.34349766913\n",
      "100.0 100.0 10 quadratic 0.736705499712\n",
      "100.0 10000.0 10 logistic 0.402065157875\n",
      "100.0 10000.0 10 quadratic 0.343043670731\n",
      "10000.0 1e-06 10 logistic 8.93419963337\n",
      "10000.0 1e-06 10 quadratic 8.848965015\n",
      "10000.0 0.0001 10 logistic 8.93420053642\n",
      "10000.0 0.0001 10 quadratic 8.84896501495\n",
      "10000.0 0.01 10 logistic 8.93428673766\n",
      "10000.0 0.01 10 quadratic 8.84896525602\n",
      "10000.0 1.0 10 logistic 8.94770623855\n",
      "10000.0 1.0 10 quadratic 8.84902042505\n",
      "10000.0 100.0 10 logistic 9.60150573075\n",
      "10000.0 100.0 10 quadratic 8.86196903652\n",
      "10000.0 10000.0 10 logistic 9.4099931007\n",
      "10000.0 10000.0 10 quadratic 9.33671895077\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "passes = 10\n",
    "for l1 in np.logspace(-6, 4, 6):\n",
    "    for l2 in np.logspace(-6, 4, 6):\n",
    "            for loss_function in ['logistic', 'quadratic']:\n",
    "                run_lerning(l1=l1, l2=l2,\n",
    "                            configs={'loss_function': loss_function, \n",
    "                                     'passes': 10,\n",
    "                                     'bit_precision': 24,\n",
    "                                     'link': 'logistic',\n",
    "                                     'cache': None,\n",
    "                                     'adaptive': None,\n",
    "                                     'quadratic': 'ff'})\n",
    "                run_predict()\n",
    "                results[(l1, l2, passes, loss_function)] = get_log_loss()\n",
    "                print l1, l2, passes, loss_function, get_log_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "отсортируем и выведем 5 наилучших варианта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   l1    |    l2   | passes | loss_function | log_loss\n",
      " 1e-06   | 100.0   | 10     | quadratic     | 0.264252848002\n",
      " 0.0001  | 100.0   | 10     | quadratic     | 0.264252860778\n",
      " 0.01    | 100.0   | 10     | quadratic     | 0.264254846591\n",
      " 1.0     | 100.0   | 10     | quadratic     | 0.264819563921\n",
      " 1e-06   | 1.0     | 10     | logistic      | 0.276531742992\n"
     ]
    }
   ],
   "source": [
    "best = sorted([(v, k) for k, v in results.items()])[:5]\n",
    "print '   l1    |    l2   | passes | loss_function | log_loss'\n",
    "for _log_loss, (l1, l2, passes, loss_function) in best:\n",
    "    print ' {:7s} | {:7s} | {:6s} | {:13s} | {}'\\\n",
    "           .format(str(l1), str(l2), str(passes), loss_function, _log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем для них посмотреть зависимость от колличества проходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 100.0 1 quadratic 0.257002600994\n",
      "1e-06 100.0 2 quadratic 0.25954456856\n",
      "1e-06 100.0 4 quadratic 0.261841735569\n",
      "1e-06 100.0 8 quadratic 0.263733963008\n",
      "1e-06 100.0 16 quadratic 0.265210519662\n",
      "1e-06 100.0 32 quadratic 0.266324675053\n",
      "0.0001 100.0 1 quadratic 0.257002646517\n",
      "0.0001 100.0 2 quadratic 0.259544601102\n",
      "0.0001 100.0 4 quadratic 0.261841830734\n",
      "0.0001 100.0 8 quadratic 0.263734016931\n",
      "0.0001 100.0 16 quadratic 0.265210499396\n",
      "0.0001 100.0 32 quadratic 0.266324711416\n",
      "0.01 100.0 1 quadratic 0.257007173093\n",
      "0.01 100.0 2 quadratic 0.259548213517\n",
      "0.01 100.0 4 quadratic 0.26184454692\n",
      "0.01 100.0 8 quadratic 0.263736143148\n",
      "0.01 100.0 16 quadratic 0.265212174382\n",
      "0.01 100.0 32 quadratic 0.266326047181\n",
      "1.0 100.0 1 quadratic 0.257936281914\n",
      "1.0 100.0 2 quadratic 0.260330530139\n",
      "1.0 100.0 4 quadratic 0.262512666395\n",
      "1.0 100.0 8 quadratic 0.264321420118\n",
      "1.0 100.0 16 quadratic 0.265740941822\n",
      "1.0 100.0 32 quadratic 0.266816152487\n",
      "1e-06 1.0 1 logistic 0.282343784837\n",
      "1e-06 1.0 2 logistic 0.279833308525\n",
      "1e-06 1.0 4 logistic 0.278074011776\n",
      "1e-06 1.0 8 logistic 0.276843274712\n",
      "1e-06 1.0 16 logistic 0.275981488733\n",
      "1e-06 1.0 32 logistic 0.275377158379\n"
     ]
    }
   ],
   "source": [
    "for _log_loss, (l1, l2, p, loss_function) in best:\n",
    "    for passes in [1, 2, 4, 8, 16, 32]:\n",
    "        run_lerning(l1=l1, l2=l2,\n",
    "                    configs={'loss_function': loss_function, \n",
    "                             'passes': passes,\n",
    "                             'bit_precision': 24,\n",
    "                             'link': 'logistic',\n",
    "                             'cache': None,\n",
    "                             'adaptive': None,\n",
    "                             'quadratic': 'ff'})\n",
    "        run_predict()\n",
    "        results[(l1, l2, passes, loss_function)] = get_log_loss()\n",
    "        print l1, l2, passes, loss_function, get_log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " N |   l1    |    l2   | passes | loss_function | log_loss\n",
      " 0 | 1e-06   | 100.0   | 1      | quadratic     | 0.257002600994\n",
      " 1 | 0.0001  | 100.0   | 1      | quadratic     | 0.257002646517\n",
      " 2 | 0.01    | 100.0   | 1      | quadratic     | 0.257007173093\n",
      " 3 | 1.0     | 100.0   | 1      | quadratic     | 0.257936281914\n",
      " 4 | 1e-06   | 100.0   | 2      | quadratic     | 0.25954456856\n",
      " 5 | 0.0001  | 100.0   | 2      | quadratic     | 0.259544601102\n",
      " 6 | 0.01    | 100.0   | 2      | quadratic     | 0.259548213517\n",
      " 7 | 1.0     | 100.0   | 2      | quadratic     | 0.260330530139\n",
      " 8 | 1e-06   | 100.0   | 4      | quadratic     | 0.261841735569\n",
      " 9 | 0.0001  | 100.0   | 4      | quadratic     | 0.261841830734\n",
      "10 | 0.01    | 100.0   | 4      | quadratic     | 0.26184454692\n",
      "11 | 1.0     | 100.0   | 4      | quadratic     | 0.262512666395\n",
      "12 | 1e-06   | 100.0   | 8      | quadratic     | 0.263733963008\n",
      "13 | 0.0001  | 100.0   | 8      | quadratic     | 0.263734016931\n",
      "14 | 0.01    | 100.0   | 8      | quadratic     | 0.263736143148\n",
      "15 | 1e-06   | 100.0   | 10     | quadratic     | 0.264252848002\n",
      "16 | 0.0001  | 100.0   | 10     | quadratic     | 0.264252860778\n",
      "17 | 0.01    | 100.0   | 10     | quadratic     | 0.264254846591\n",
      "18 | 1.0     | 100.0   | 8      | quadratic     | 0.264321420118\n",
      "19 | 1.0     | 100.0   | 10     | quadratic     | 0.264819563921\n",
      "20 | 0.0001  | 100.0   | 16     | quadratic     | 0.265210499396\n",
      "21 | 1e-06   | 100.0   | 16     | quadratic     | 0.265210519662\n",
      "22 | 0.01    | 100.0   | 16     | quadratic     | 0.265212174382\n",
      "23 | 1.0     | 100.0   | 16     | quadratic     | 0.265740941822\n",
      "24 | 1e-06   | 100.0   | 32     | quadratic     | 0.266324675053\n",
      "25 | 0.0001  | 100.0   | 32     | quadratic     | 0.266324711416\n",
      "26 | 0.01    | 100.0   | 32     | quadratic     | 0.266326047181\n",
      "27 | 1.0     | 100.0   | 32     | quadratic     | 0.266816152487\n",
      "28 | 1e-06   | 1.0     | 32     | logistic      | 0.275377158379\n",
      "29 | 1e-06   | 1.0     | 16     | logistic      | 0.275981488733\n",
      "30 | 1e-06   | 1.0     | 10     | logistic      | 0.276531742992\n",
      "31 | 0.0001  | 1.0     | 10     | logistic      | 0.276544395309\n",
      "32 | 1e-06   | 1.0     | 8      | logistic      | 0.276843274712\n",
      "33 | 0.01    | 1.0     | 10     | logistic      | 0.277992297239\n",
      "34 | 1e-06   | 1.0     | 4      | logistic      | 0.278074011776\n",
      "35 | 1e-06   | 1.0     | 2      | logistic      | 0.279833308525\n",
      "36 | 1.0     | 1.0     | 10     | quadratic     | 0.281205872186\n",
      "37 | 1.0     | 0.01    | 10     | quadratic     | 0.281957773138\n",
      "38 | 1.0     | 0.0001  | 10     | quadratic     | 0.281963770835\n",
      "39 | 1.0     | 1e-06   | 10     | quadratic     | 0.281963828407\n"
     ]
    }
   ],
   "source": [
    "best = sorted([(v, k) for k, v in results.items()])[:40]\n",
    "print ' N |   l1    |    l2   | passes | loss_function | log_loss'\n",
    "i = 0\n",
    "for _log_loss, (l1, l2, passes, loss_function) in best:\n",
    "    print '{:2} | {:7s} | {:7s} | {:6s} | {:13s} | {}'\\\n",
    "           .format(i, str(l1), str(l2), str(passes), loss_function, _log_loss)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из результатов quadratic ближе к случайному лесу, чем logistic. Попробуем залить на сайт https://www.kaggle.com/c/titanic некоторые из вариантов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_log_loss, (l1, l2, passes, loss_function) = best[0]\n",
    "run_lerning(l1=l1, l2=l2,\n",
    "            configs={'loss_function': loss_function, \n",
    "                     'passes': passes,\n",
    "                     'bit_precision': 24,\n",
    "                     'link': 'logistic',\n",
    "                     'cache': None,\n",
    "                     'adaptive': None,\n",
    "                     'quadratic': 'ff'})\n",
    "run_predict()\n",
    "scores = read_predict('/ssd_data/titanic/predict.txt')\n",
    "y_pred = np.array([int(score > 0.5) for score in scores])\n",
    "res = pd.DataFrame({'PassengerId': np.array(range(892, 892 + 418)),\n",
    "                    'Survived': y_pred})\n",
    "res.to_csv('/ssd_data/titanic/predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получился результат 0.77512 (2734 место)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_log_loss, (l1, l2, passes, loss_function) = best[28]\n",
    "run_lerning(l1=l1, l2=l2,\n",
    "            configs={'loss_function': loss_function, \n",
    "                     'passes': passes,\n",
    "                     'bit_precision': 24,\n",
    "                     'link': 'logistic',\n",
    "                     'cache': None,\n",
    "                     'adaptive': None,\n",
    "                     'quadratic': 'ff'})\n",
    "run_predict()\n",
    "scores = read_predict('/ssd_data/titanic/predict.txt')\n",
    "y_pred = np.array([int(score > 0.5) for score in scores])\n",
    "res = pd.DataFrame({'PassengerId': np.array(range(892, 892 + 418)),\n",
    "                    'Survived': y_pred})\n",
    "res.to_csv('/ssd_data/titanic/predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получился тоже самое. Залил результат случайных деревьев, получил результат 0.78469. Лучше, но не значительно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
